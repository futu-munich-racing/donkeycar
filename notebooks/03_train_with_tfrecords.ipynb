{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN_SAMPLES = 35998\n",
    "NUM_VAL_SAMPLES = 5368\n",
    "\n",
    "VERBOSE = True\n",
    "MIN_DELTA = 0.005\n",
    "PATIENCE = 5\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100\n",
    "\n",
    "MODEL_NAME = 'simple_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_image_dataset = tf.data.TFRecordDataset('data/train.tfrecord')\n",
    "#\n",
    "# Create a dictionary describing the features.\n",
    "#image_feature_description = {\n",
    "#    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "#    'angle': tf.io.FixedLenFeature([], tf.float32),\n",
    "#    'throttle': tf.io.FixedLenFeature([], tf.float32)\n",
    "#}\n",
    "#\n",
    "#def _parse_image_function(example_proto):\n",
    "#  # Parse the input tf.Example proto using the dictionary above.\n",
    "#  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "#\n",
    "#parsed_image_dataset = raw_image_dataset.map(_parse_image_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_jpeg(image_buffer, scope=None):\n",
    "    \"\"\"Decode a JPEG string into one 3-D float image Tensor.\n",
    "    Args:\n",
    "        image_buffer: scalar string Tensor.\n",
    "        scope: Optional scope for name_scope.\n",
    "    Returns:\n",
    "        3-D float Tensor with values ranging from [0, 1).\n",
    "    \"\"\"\n",
    "    with tf.name_scope(values=[image_buffer], name=scope,\n",
    "                       default_name='decode_jpeg'):\n",
    "        # Decode the string as an RGB JPEG.\n",
    "        # Note that the resulting image contains an unknown height\n",
    "        # and width that is set dynamically by decode_jpeg. In other\n",
    "        # words, the height and width of image is unknown at compile-i\n",
    "        # time.\n",
    "        image = tf.image.decode_jpeg(image_buffer, channels=3)\n",
    "\n",
    "        # After this point, all image pixels reside in [0,1)\n",
    "        # until the very end, when they're rescaled to (-1, 1).\n",
    "        # The various adjust_* ops all require this range for dtype\n",
    "        # float.\n",
    "        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "        return image\n",
    "\n",
    "def _parse_fn(example_serialized, is_training=False):\n",
    "    \"\"\" ...\n",
    "    \"\"\"\n",
    "    feature_map = {\n",
    "        'image': tf.FixedLenFeature([], dtype=tf.string, default_value=''),\n",
    "        'angle': tf.FixedLenFeature([], dtype=tf.float32, default_value=0.0),\n",
    "        'throttle': tf.FixedLenFeature([], dtype=tf.float32, default_value=0.0),\n",
    "    }\n",
    "    \n",
    "    parsed = tf.parse_single_example(example_serialized, feature_map)\n",
    "    image = decode_jpeg(parsed['image'])\n",
    "    image = tf.reshape(image, (1, 240, 360, 3))\n",
    "    return (image, (parsed['angle'], parsed['throttle']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(tfrecords_dir, subset, batch_size):\n",
    "    \"\"\"Read TFRecords files and turn them into a TFRecordDataset.\"\"\"\n",
    "    files = tf.matching_files(os.path.join(tfrecords_dir, '%s-*' % subset))\n",
    "    shards = tf.data.Dataset.from_tensor_slices(files)\n",
    "    shards = shards.shuffle(tf.cast(tf.shape(files)[0], tf.int64))\n",
    "    shards = shards.repeat()\n",
    "    dataset = shards.interleave(tf.data.TFRecordDataset, cycle_length=4)\n",
    "    dataset = dataset.shuffle(buffer_size=8192)\n",
    "    parser = partial(\n",
    "        _parse_fn, is_training=True if subset == 'train' else False)\n",
    "    dataset = dataset.apply(\n",
    "        tf.data.experimental.map_and_batch(\n",
    "            map_func=parser,\n",
    "            batch_size=batch_size,\n",
    "            num_parallel_calls=config.NUM_DATA_WORKERS))\n",
    "    dataset = dataset.prefetch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image_dataset = tf.data.TFRecordDataset('data/train.tfrecord')\n",
    "parsed_image_dataset = raw_image_dataset.map(_parse_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_validation_set = tf.data.TFRecordDataset('data/val.tfrecord')\n",
    "parsed_validation_set = raw_image_dataset.map(_parse_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.layers import Convolution2D, Convolution3D\n",
    "from tensorflow.python.keras.layers import MaxPooling2D, MaxPooling3D\n",
    "from tensorflow.python.keras.activations import relu\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.python.keras.layers import Cropping2D, Cropping3D\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_loss_angle = 0.9\n",
    "weight_loss_throttle = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_2d_model(img_dims, crop_margin_from_top=80):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    img_in = Input(shape=(img_dims), name='img_in')\n",
    "\n",
    "    x = img_in\n",
    "\n",
    "    x = Cropping2D(((crop_margin_from_top, 0), (0, 0)))(x)\n",
    "\n",
    "    # Define convolutional neural network to extract features from the images\n",
    "    x = Convolution2D(filters=24, kernel_size=(5, 5), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Convolution2D(filters=24, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Convolution2D(filters=24, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Convolution2D(filters=24, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Convolution2D(filters=24, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Convolution2D(filters=32, kernel_size=(5, 5), strides=(2, 2), activation='relu')(x)\n",
    "    #x = Convolution2D(filters=64, kernel_size=(5, 5), strides=(2, 2), activation='relu')(x)\n",
    "    #x = Convolution2D(filters=64, kernel_size=(3, 3), strides=(2, 2), activation='relu')(x)\n",
    "    #x = Convolution2D(filters=64, kernel_size=(3, 3), strides=(1, 1), activation='relu')(x)\n",
    "\n",
    "    # Define decision layers to predict steering and throttle\n",
    "    x = Flatten(name='flattened')(x)\n",
    "    #x = Dense(units=100, activation='linear')(x)\n",
    "    #x = Dropout(rate=.5)(x)\n",
    "    x = Dense(units=10, activation='linear')(x)\n",
    "    x = Dropout(rate=.5)(x)\n",
    "    # categorical output of the angle\n",
    "    angle_out = Dense(units=1, activation='linear', name='angle_out')(x)\n",
    "\n",
    "    # continous output of throttle\n",
    "    throttle_out = Dense(units=1, activation='linear', name='throttle_out')(x)\n",
    "\n",
    "    model = Model(inputs=[img_in], outputs=[angle_out, throttle_out])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss={'angle_out': 'mean_squared_error',\n",
    "                      'throttle_out': 'mean_squared_error'},\n",
    "                loss_weights={'angle_out': weight_loss_angle,\n",
    "                              'throttle_out': weight_loss_throttle},\n",
    "                metrics=['mse', 'mae', 'mape'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_in (InputLayer)             (None, 240, 360, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d (Cropping2D)         (None, 160, 360, 3)  0           img_in[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 156, 356, 24) 1824        cropping2d[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 78, 178, 24)  0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 76, 176, 24)  5208        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 38, 88, 24)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 36, 86, 24)   5208        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 18, 43, 24)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 41, 24)   5208        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 20, 24)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 6, 18, 24)    5208        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 3, 9, 24)     0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flattened (Flatten)             (None, 648)          0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           6490        flattened[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "angle_out (Dense)               (None, 1)            11          dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "throttle_out (Dense)            (None, 1)            11          dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 29,168\n",
      "Trainable params: 29,168\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_2d_model(img_dims=[240, 360, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model will be stored to: ./simple_model.h5\n"
     ]
    }
   ],
   "source": [
    "#TODO: based on running locally or valohai the dir should be changed\n",
    "#saved_model_path = os.path.join(datadir, 'models', model_file_name)\n",
    "outputs_dir = os.getenv('VH_OUTPUTS_DIR', './')\n",
    "output_file = os.path.join(outputs_dir, '%s.h5' % MODEL_NAME)\n",
    "\n",
    "\n",
    "print('model will be stored to: %s' % output_file)\n",
    "\n",
    "# checkpoint to save model after each epoch\n",
    "save_best = ModelCheckpoint(output_file,\n",
    "                            monitor='val_loss',\n",
    "                            verbose=VERBOSE,\n",
    "                            save_best_only=True,\n",
    "                            mode='min')\n",
    "\n",
    "# stop training if the validation error stops improving.\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           min_delta=MIN_DELTA,\n",
    "                           patience=PATIENCE,\n",
    "                           verbose=VERBOSE,\n",
    "                           mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3180/35998 [=>............................] - ETA: 3:08:30 - loss: 0.2270 - angle_out_loss: 0.2508 - throttle_out_loss: 0.0130 - angle_out_mean_squared_error: 0.2508 - angle_out_mean_absolute_error: 0.3994 - angle_out_mean_absolute_percentage_error: 95308808.0000 - throttle_out_mean_squared_error: 0.0130 - throttle_out_mean_absolute_error: 0.0751 - throttle_out_mean_absolute_percentage_error: 36675.6797"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-95d11898720c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_VAL_SAMPLES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           epochs=1)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    852\u001b[0m     elif distributed_training_utils.is_tpu_strategy(\n\u001b[1;32m    853\u001b[0m         self._distribution_strategy):\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mbatch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;31m# will be handled by on_epoch_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(parsed_image_dataset,\n",
    "          validation_data = parsed_image_dataset,\n",
    "          steps_per_epoch = NUM_TRAIN_SAMPLES // BATCH_SIZE,\n",
    "          validation_steps = NUM_VAL_SAMPLES // BATCH_SIZE,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
