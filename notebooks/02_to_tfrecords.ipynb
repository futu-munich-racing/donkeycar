{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tub_data_to_records(data_dir):\n",
    "    # Get a list of directories starting with word tub\n",
    "    tub_dirs = glob.glob(os.path.join(data_dir, 'tub*'))\n",
    "    # Sort the directories\n",
    "    tub_dirs.sort()\n",
    "    tub_dirs = [tub_dir for tub_dir in tub_dirs]\n",
    "    print(tub_dirs)\n",
    "    # Go through the directories \n",
    "    records = []\n",
    "    for tub_dir in tub_dirs:\n",
    "        json_files = glob.glob(os.path.join(tub_dir, 'record_*.json'))\n",
    "        if len(json_files) == 0:\n",
    "            tub_dir = os.path.join(tub_dir, 'tub')\n",
    "            json_files = glob.glob(os.path.join(tub_dir, 'record_*.json'))\n",
    "        n = len(json_files)\n",
    "        i = 0\n",
    "        cnt = 0\n",
    "        while cnt < n:\n",
    "            json_file = os.path.join(tub_dir, 'record_%d.json' % i)\n",
    "            try:\n",
    "                data = json.load(open(json_file, 'r'))\n",
    "                data['img_path'] = os.path.join(os.path.basename(tub_dir), data['cam/image_array'])\n",
    "                records.append(data)\n",
    "                cnt += 1\n",
    "            except:\n",
    "                pass\n",
    "            i += 1\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [120, 180])\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "def load_image(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(image, angle, throttle):\n",
    "    \"\"\"\n",
    "    Creates a tf.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping the feature name to the tf.Example-compatible\n",
    "    # data type.\n",
    "    feature = {\n",
    "      'image': _bytes_feature(image),\n",
    "      'angle': _float_feature(angle),\n",
    "      'throttle': _float_feature(throttle),\n",
    "    }\n",
    "\n",
    "    # Create a Features message using tf.train.Example.\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/train/tub9', 'data/train/tub_2019-05-08_1240', 'data/train/tub_teemu_08052019']\n"
     ]
    }
   ],
   "source": [
    "train_records = load_tub_data_to_records('data/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cam/image_array': '0_cam-image_array_.jpg',\n",
       " 'timestamp': '2019-05-08 09:21:58.490116',\n",
       " 'user/throttle': 3.051850947599719e-05,\n",
       " 'user/angle': 0.0,\n",
       " 'user/mode': 'user',\n",
       " 'img_path': 'tub9/0_cam-image_array_.jpg'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = train_records[0]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm data/train.tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 35998 0.0\n",
      "1000 35998 2.7779321073392964\n",
      "2000 35998 5.555864214678593\n",
      "3000 35998 8.33379632201789\n",
      "4000 35998 11.111728429357186\n",
      "5000 35998 13.889660536696484\n",
      "6000 35998 16.66759264403578\n",
      "7000 35998 19.445524751375075\n",
      "8000 35998 22.22345685871437\n",
      "9000 35998 25.00138896605367\n",
      "10000 35998 27.779321073392968\n",
      "11000 35998 30.557253180732264\n",
      "12000 35998 33.33518528807156\n",
      "13000 35998 36.11311739541085\n",
      "14000 35998 38.89104950275015\n",
      "15000 35998 41.668981610089446\n",
      "16000 35998 44.44691371742874\n",
      "17000 35998 47.224845824768046\n",
      "18000 35998 50.00277793210734\n",
      "19000 35998 52.78071003944664\n",
      "20000 35998 55.558642146785935\n",
      "21000 35998 58.33657425412523\n",
      "22000 35998 61.11450636146453\n",
      "23000 35998 63.892438468803824\n",
      "24000 35998 66.67037057614311\n",
      "25000 35998 69.44830268348241\n",
      "26000 35998 72.2262347908217\n",
      "27000 35998 75.004166898161\n",
      "28000 35998 77.7820990055003\n",
      "29000 35998 80.5600311128396\n",
      "30000 35998 83.33796322017889\n",
      "31000 35998 86.11589532751819\n",
      "32000 35998 88.89382743485749\n",
      "33000 35998 91.6717595421968\n",
      "34000 35998 94.44969164953609\n",
      "35000 35998 97.22762375687539\n"
     ]
    }
   ],
   "source": [
    "# Write the `tf.Example` observations to the file.\n",
    "with tf.io.TFRecordWriter('data/train.tfrecord') as writer:\n",
    "    for i, record in enumerate(train_records):\n",
    "        # parse fields\n",
    "        #img = load_image(os.path.join('data/train/', record['img_path']))\n",
    "        image_string = open(os.path.join('data/train/', record['img_path']), 'rb').read()\n",
    "        angle = record['user/angle']\n",
    "        throttle = record['user/throttle']\n",
    "        example = serialize_example(image_string, angle, throttle)\n",
    "        writer.write(example)\n",
    "        if i % 1000 == 0:\n",
    "            print(i, len(train_records), 100*i/len(train_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3599.8"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/val/tub_2019-06-04_1556', 'data/val/tub_2019-06-05_1709', 'data/val/tub_2019-06-05_1724']\n",
      "0 5368 0.0\n",
      "1000 5368 18.628912071535023\n",
      "2000 5368 37.257824143070046\n",
      "3000 5368 55.886736214605065\n",
      "4000 5368 74.51564828614009\n",
      "5000 5368 93.14456035767512\n"
     ]
    }
   ],
   "source": [
    "val_records = load_tub_data_to_records('data/val/')\n",
    "\n",
    "with tf.io.TFRecordWriter('data/val.tfrecord') as writer:\n",
    "    for i, record in enumerate(val_records):\n",
    "        # parse fields\n",
    "        image_string = open(os.path.join('data/val/', record['img_path']), 'rb').read()\n",
    "        angle = record['user/angle']\n",
    "        throttle = record['user/throttle']\n",
    "        example = serialize_example(image_string, angle, throttle)\n",
    "        writer.write(example)\n",
    "        if i % 1000 == 0:\n",
    "            print(i, len(val_records), 100*i/len(val_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 35998 and validation samples: 5368\n"
     ]
    }
   ],
   "source": [
    "print('Training samples: %d and validation samples: %d' % (len(train_records), len(val_records)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
